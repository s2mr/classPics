//
//  CameraViewController.swift
//  classPics
//
//  Created by Kazumasa Shimomura on 2016/10/03.
//  Copyright Â© 2016å¹´ Kazumasa Shimomura. All rights reserved.
//

import UIKit
import AVFoundation
import CoreMotion
//import EasyImagy

class CameraViewController: UIViewController, AVCaptureVideoDataOutputSampleBufferDelegate, UIGestureRecognizerDelegate  {
    
    let motionManager: CMMotionManager = CMMotionManager()
    var quaternion: CMQuaternion!

    
    var input:AVCaptureDeviceInput!
    var output:AVCaptureVideoDataOutput!
    var session:AVCaptureSession!
    var camera:AVCaptureDevice!
    var imageView:UIImageView!
    var attrText: NSMutableAttributedString!
    var label:UILabel!
    
    let ad = UIApplication.shared.delegate as! AppDelegate
    var subjectName = "æœªåˆ†é¡"
    
    override func viewDidLoad() {
        super.viewDidLoad()
        
        motionManager.deviceMotionUpdateInterval = 0.05 // 20Hz
        
        motionManager.startDeviceMotionUpdates( to: OperationQueue.current!, withHandler:{
            deviceManager, error in
            let attitude: CMAttitude = deviceManager!.attitude
            
            self.quaternion = attitude.quaternion
            print(self.quaternion.z)
            
        })
        
        attrText = NSMutableAttributedString()
        
        attrText.mutableString.setString("æœªåˆ†é¡\nâ–¼")
        
        // 1è¡Œç›® 14
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 17)], range: NSMakeRange(0, 3))
        // 2è¡Œç›® 10
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 10)], range: NSMakeRange(4, 1))
        
//        self.label.attributedText = attrText
        
        label = UILabel(frame: CGRect(x: 0, y: 0, width: 480, height: 44))
        label.numberOfLines = 2
//        label.text = "æœªåˆ†é¡\nğŸ”»"
        label.textAlignment = .center
        label.attributedText = attrText
        
        let gestureRecognizer = UITapGestureRecognizer(target: self, action: #selector(tapped(tapGestureRecognizer:)))
        label.addGestureRecognizer(gestureRecognizer)
        label.isUserInteractionEnabled = true

        
        navigationItem.titleView = label
        
        // ç”»é¢ã‚¿ãƒƒãƒ—ã§ãƒ”ãƒ³ãƒˆã‚’ã‚ã‚ã›ã‚‹
        let tapGesture = UITapGestureRecognizer(target: self, action: #selector(tappedScreen))
        let pinchGesture = UIPinchGestureRecognizer(target: self, action: #selector(pinchedGesture))
        
        // ãƒ‡ãƒªã‚²ãƒ¼ãƒˆã‚’ã‚»ãƒƒãƒˆ
        tapGesture.delegate = self
        
        // Viewã«ã‚¿ãƒƒãƒ—ã€ãƒ”ãƒ³ãƒã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚’è¿½åŠ 
        self.view.addGestureRecognizer(tapGesture)
        self.view.addGestureRecognizer(pinchGesture)
        
        let underView = UIView(frame: CGRect(origin: CGPoint(x:0,y:0), size: CGSize(width: self.view.frame.size.width, height:self.view.frame.size.height/8)))
        underView.center = CGPoint(x: self.view.frame.size.width/2, y: self.view.frame.size.height-underView.frame.size.height/2)
        underView.backgroundColor = UIColor.black.withAlphaComponent(0.4)
        self.view.addSubview(underView)
        
        let shutterButton = UIButton(frame: CGRect(origin: CGPoint(x:0,y:0), size: CGSize(width: underView.frame.size.height-15, height: underView.frame.size.height-15)))
        shutterButton.center = CGPoint(x: underView.frame.size.width/2, y: underView.frame.size.height/2)
        shutterButton.backgroundColor = UIColor.white.withAlphaComponent(0)
        shutterButton.layer.masksToBounds = true
        shutterButton.layer.cornerRadius = shutterButton.frame.size.width/2
        shutterButton.layer.borderColor = UIColor.white.cgColor
        shutterButton.layer.borderWidth = 6
        shutterButton.addTarget(self, action: #selector(tapedShutterButton), for: .touchUpInside)
        underView.addSubview(shutterButton)
        
        let shutterShadowView = UIView(frame: CGRect(origin: CGPoint(x:0,y:0), size: CGSize(width: shutterButton.frame.size.height-18, height: shutterButton.frame.size.height-18)))
        shutterShadowView.center = CGPoint(x: shutterButton.frame.size.width/2, y: shutterButton.frame.size.height/2)
        shutterShadowView.backgroundColor = UIColor.white
        shutterShadowView.layer.masksToBounds = true
        shutterShadowView.layer.cornerRadius = shutterShadowView.frame.size.width/2
        // shutterShadowView.layer.borderColor = UIColor.blackColor().CGColor
        // shutterShadowView.layer.borderWidth = 3
        shutterShadowView.isUserInteractionEnabled = false
        shutterButton.addSubview(shutterShadowView)
        
        /*
        let closeButton = UIButton()
        closeButton.setTitle("é–‰ã˜ã‚‹", for: .normal)
        closeButton.setTitleColor(UIColor.white, for: .normal)
        closeButton.sizeToFit()
        closeButton.center = CGPoint(x: (underView.frame.size.width+shutterButton.center.x+shutterButton.frame.size.width/2)/2, y: underView.frame.size.height/2)
        closeButton.addTarget(self, action: #selector(tapedCloseButton), for: .touchUpInside)
        underView.addSubview(closeButton)
 */
        
        // ã‚¹ã‚¯ãƒªãƒ¼ãƒ³è¨­å®š
        setupDisplay()
        
        // ã‚«ãƒ¡ãƒ©ã®è¨­å®š
        setupCamera()
        
    }
    
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)

        let string = "\(subjectName)\nâ–¼"
        
        attrText.mutableString.setString(string)
        
        
        
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 17)], range: NSMakeRange(0, string.characters.count))
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 10)], range: NSMakeRange(string.characters.count-1, 1))
        label.attributedText = attrText
        navigationItem.titleView = label
        
        print("Subject Name is : \(subjectName)")
    }
    
    // ãƒ¡ãƒ¢ãƒªè§£æ”¾
    override func viewDidDisappear(_ animated: Bool) {
        super.viewDidDisappear(animated)
        // camera stop ãƒ¡ãƒ¢ãƒªè§£æ”¾
        session.stopRunning()
        
        for output in session.outputs {
            session.removeOutput(output as? AVCaptureOutput)
        }
        
        for input in session.inputs {
            session.removeInput(input as? AVCaptureInput)
        }
        
        session = nil
        camera = nil
        
        subjectName = ""
    }
    
    func setupDisplay(){
        //ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã®å¹…
        let screenWidth = UIScreen.main.bounds.size.width;
        //ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã®é«˜ã•
        let screenHeight = UIScreen.main.bounds.size.height;
        
        // ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®æ˜ åƒã‚’æ˜ ã™imageViewã®ä½œæˆ
        if let iv = imageView {
            //ä»¥å‰ã®imageViewãŒã‚ã‚Œã°å‰¥ãŒã—ã¦ãŠã
            iv.removeFromSuperview()
        }
        imageView = UIImageView()
        imageView.frame = CGRect(x:0.0, y:0.0, width:screenWidth, height:screenHeight)
        view.addSubview(imageView)
        view.sendSubview(toBack: imageView)
    }
    
    func setupCamera(){
        // AVCaptureSession: ã‚­ãƒ£ãƒ—ãƒãƒ£ã«é–¢ã™ã‚‹å…¥åŠ›ã¨å‡ºåŠ›ã®ç®¡ç†
        session = AVCaptureSession()
        
        // sessionPreset: ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ»ã‚¯ã‚ªãƒªãƒ†ã‚£ã®è¨­å®š
        session.sessionPreset = AVCaptureSessionPresetHigh
        
        let a = AVCaptureDeviceDiscoverySession(deviceTypes: [.builtInWideAngleCamera], mediaType: AVMediaTypeVideo, position: .back)
        
        // AVCaptureDevice: ã‚«ãƒ¡ãƒ©ã‚„ãƒã‚¤ã‚¯ãªã©ã®ãƒ‡ãƒã‚¤ã‚¹ã‚’è¨­å®š
        for caputureDevice in (a?.devices)! {
            // èƒŒé¢ã‚«ãƒ¡ãƒ©ã‚’å–å¾—
            if (caputureDevice as AnyObject).position == AVCaptureDevicePosition.back {
                camera = caputureDevice
            }
        }
        
        // ã‚«ãƒ¡ãƒ©ã‹ã‚‰ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
        do {
            input = try AVCaptureDeviceInput(device: camera) as AVCaptureDeviceInput
        } catch let error as NSError {
            print(error)
        }
        
        // å…¥åŠ›ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¿½åŠ 
        if(session.canAddInput(input)) {
            session.addInput(input)
        }
        
        // AVCaptureVideoDataOutput:å‹•ç”»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã«è¨­å®š
        output = AVCaptureVideoDataOutput()
        
        // å‡ºåŠ›ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«è¿½åŠ 
        if(session.canAddOutput(output)) {
            session.addOutput(output)
        }
        
        // ãƒ”ã‚¯ã‚»ãƒ«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ 32bit BGR + A ã¨ã™ã‚‹
        output.videoSettings = [kCVPixelBufferPixelFormatTypeKey as AnyHashable : Int(kCVPixelFormatType_32BGRA)]
        
        // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ãŸã‚ã®ã‚µãƒ–ã‚¹ãƒ¬ãƒƒãƒ‰ç”¨ã®ã‚·ãƒªã‚¢ãƒ«ã‚­ãƒ¥ãƒ¼ã‚’ç”¨æ„
        output.setSampleBufferDelegate(self, queue: DispatchQueue.main)
        
        output.alwaysDiscardsLateVideoFrames = true
        
        session.startRunning()
        
        // deviceã‚’ãƒ­ãƒƒã‚¯ã—ã¦è¨­å®š
        do {
            try camera.lockForConfiguration()
            // ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ
            camera.activeVideoMinFrameDuration = CMTimeMake(1, 30)
            camera.unlockForConfiguration()
        } catch _ {
        }
    }
    
    
    // æ–°ã—ã„ã‚­ãƒ£ãƒ—ãƒãƒ£ã®è¿½åŠ ã§å‘¼ã°ã‚Œã‚‹
    func captureOutput(_ captureOutput: AVCaptureOutput!, didOutputSampleBuffer sampleBuffer: CMSampleBuffer!, from connection: AVCaptureConnection!) {
        
        // ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸsampleBufferã‹ã‚‰UIImageã‚’ä½œæˆ
        let image:UIImage = self.captureImage(sampleBuffer: sampleBuffer)
        
        // ã‚«ãƒ¡ãƒ©ã®ç”»åƒã‚’ç”»é¢ã«è¡¨ç¤º
        DispatchQueue.main.async {
            self.imageView.image = image
        }
    }
    
    // sampleBufferã‹ã‚‰UIImageã‚’ä½œæˆ
    func captureImage(sampleBuffer:CMSampleBuffer) -> UIImage{
        
        // Sampling Bufferã‹ã‚‰ç”»åƒã‚’å–å¾—
        let imageBuffer:CVImageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer)!
        
        // pixel buffer ã®ãƒ™ãƒ¼ã‚¹ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒ­ãƒƒã‚¯
        CVPixelBufferLockBaseAddress(imageBuffer, CVPixelBufferLockFlags(rawValue: CVOptionFlags(0)))
        
        let baseAddress:UnsafeMutableRawPointer = CVPixelBufferGetBaseAddressOfPlane(imageBuffer, 0)!
        
        let bytesPerRow:Int = CVPixelBufferGetBytesPerRow(imageBuffer)
        let width:Int = CVPixelBufferGetWidth(imageBuffer)
        let height:Int = CVPixelBufferGetHeight(imageBuffer)
        
        // è‰²ç©ºé–“
        let colorSpace:CGColorSpace = CGColorSpaceCreateDeviceRGB()
        
        let newContext:CGContext = CGContext(data: baseAddress, width: width, height: height, bitsPerComponent: 8, bytesPerRow: bytesPerRow, space: colorSpace,  bitmapInfo: CGImageAlphaInfo.premultipliedFirst.rawValue|CGBitmapInfo.byteOrder32Little.rawValue)!
        
        let imageRef:CGImage = newContext.makeImage()!
        let resultImage = UIImage(cgImage: imageRef, scale: 1.0, orientation: UIImageOrientation.right)
        
        return resultImage
    }
    
    
    // ã‚¿ãƒƒãƒ—ã‚¤ãƒ™ãƒ³ãƒˆ.
    func tapedShutterButton(sender: UIButton) {
        takeStillPicture()
        
        self.imageView.alpha = 0.4
        
        UIView.animate(withDuration: 0.5, animations: {
            self.imageView.alpha = 1
        })
    }
    
    func takeStillPicture(){
//        if var _:AVCaptureConnection? = output.connection(withMediaType: AVMediaTypeVideo){
//            // ã‚¢ãƒ«ãƒãƒ ã«è¿½åŠ 
//            UIImageWriteToSavedPhotosAlbum(self.imageView.image!, self, nil, nil)
//        }
        
        let date = Date()
        let formatter = DateFormatter()
        formatter.dateFormat = "yyyy-MM-dd-hh:mm:ss"
        
        let path = NSHomeDirectory() + "/Library/"
        let fileName = formatter.string(from: date)
        let filePath = path + fileName
        
        var imageToSave:UIImage
        
        if quaternion.z > 0.35{
            //landscapeRight
            //ãã®ã¾ã¾
            imageToSave = UIImage(cgImage: imageView.image as! CGImage, scale: (imageView.image?.scale)!, orientation: .up)
        }else if quaternion.z < -0.25{
            //landscapeLeft
            //180åº¦å›è»¢
            imageToSave =  UIImage(cgImage: (imageView.image?.cgImage)!, scale: (imageView.image?.scale)!, orientation: .down)
        }else if quaternion.z > 0.60{
            //upsidedown
            //å·¦ã«90åº¦å›è»¢
            imageToSave =  UIImage(cgImage: imageView.image as! CGImage, scale: (imageView.image?.scale)!, orientation: .right)

        }else {
            //portrait
            //å³ã«90åº¦å›è»¢
            imageToSave =  UIImage(cgImage: (imageView.image?.cgImage)!, scale: (imageView.image?.scale)!, orientation:.left)

        }
        
        let data = UIImagePNGRepresentation(imageToSave)
        
        
        
        try! data?.write(to: URL(fileURLWithPath: filePath))
        
        if subjectName == "" || subjectName == "æœªåˆ†é¡"{
            ad.name[fileName] = "æœªåˆ†é¡"
        }else{
            ad.name[fileName] = "subjectName"
        }
        
        ad.save(object: ad.name as AnyObject, key: "PHOTOINFO")
        
    }
    
    func tapedCloseButton(sender: UIButton) {
        print("Close")
        
        // å‰ã®ç”»é¢ã«æˆ»ã‚‹ã¨ã
        // self.dismissViewControllerAnimated(true, completion: nil)
    }
    
    let focusView = UIView()
    
    func tappedScreen(gestureRecognizer: UITapGestureRecognizer) {
        let tapCGPoint = gestureRecognizer.location(ofTouch: 0, in: gestureRecognizer.view)
        focusView.frame.size = CGSize(width: 120, height: 120)
        focusView.center = tapCGPoint
        focusView.backgroundColor = UIColor.white.withAlphaComponent(0)
        focusView.layer.borderColor = UIColor.white.cgColor
        focusView.layer.borderWidth = 2
        focusView.alpha = 1
        imageView.addSubview(focusView)
        
        UIView.animate(withDuration: 0.5, animations: {
            self.focusView.frame.size = CGSize(width: 80, height: 80)
            self.focusView.center = tapCGPoint
            }, completion: { Void in
                UIView.animate(withDuration: 0.5, animations: {
                    self.focusView.alpha = 0
                })
        })
        
        self.focusWithMode(focusMode: AVCaptureFocusMode.autoFocus, exposeWithMode: AVCaptureExposureMode.autoExpose, atDevicePoint: tapCGPoint, motiorSubjectAreaChange: true)
    }
    
    var oldZoomScale: CGFloat = 1.0
    
    func pinchedGesture(gestureRecgnizer: UIPinchGestureRecognizer) {
        do {
            try camera.lockForConfiguration()
            // ã‚ºãƒ¼ãƒ ã®æœ€å¤§å€¤
            let maxZoomScale: CGFloat = 6.0
            // ã‚ºãƒ¼ãƒ ã®æœ€å°å€¤
            let minZoomScale: CGFloat = 1.0
            // ç¾åœ¨ã®ã‚«ãƒ¡ãƒ©ã®ã‚ºãƒ¼ãƒ åº¦
            var currentZoomScale: CGFloat = camera.videoZoomFactor
            // ãƒ”ãƒ³ãƒã®åº¦åˆã„
            let pinchZoomScale: CGFloat = gestureRecgnizer.scale
            
            // ãƒ”ãƒ³ãƒã‚¢ã‚¦ãƒˆã®æ™‚ã€å‰å›ã®ã‚ºãƒ¼ãƒ ã«ä»Šå›ã®ã‚ºãƒ¼ãƒ -1ã‚’æŒ‡å®š
            // ä¾‹: å‰å›3.0, ä»Šå›1.2ã®ã¨ãã€currentZoomScale=3.2
            if pinchZoomScale > 1.0 {
                currentZoomScale = oldZoomScale+pinchZoomScale-1
            } else {
                currentZoomScale = oldZoomScale-(1-pinchZoomScale)*oldZoomScale
            }
            
            // æœ€å°å€¤ã‚ˆã‚Šå°ã•ãã€æœ€å¤§å€¤ã‚ˆã‚Šå¤§ãããªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹
            if currentZoomScale < minZoomScale {
                currentZoomScale = minZoomScale
            }
            else if currentZoomScale > maxZoomScale {
                currentZoomScale = maxZoomScale
            }
            
            // ç”»é¢ã‹ã‚‰æŒ‡ãŒé›¢ã‚ŒãŸã¨ãã€stateãŒEndedã«ãªã‚‹ã€‚
            if gestureRecgnizer.state == .ended {
                oldZoomScale = currentZoomScale
            }
            
            camera.videoZoomFactor = currentZoomScale
            camera.unlockForConfiguration()
        } catch {
            // handle error
            return
        }
    }
    
    func focusWithMode(focusMode : AVCaptureFocusMode, exposeWithMode expusureMode :AVCaptureExposureMode, atDevicePoint point:CGPoint, motiorSubjectAreaChange monitorSubjectAreaChange:Bool) {
        
        
        DispatchQueue.global().async {
            let device : AVCaptureDevice = self.input.device
            
            do {
                try device.lockForConfiguration()
                if(device.isFocusPointOfInterestSupported && device.isFocusModeSupported(focusMode)){
                    device.focusPointOfInterest = point
                    device.focusMode = focusMode
                }
                if(device.isExposurePointOfInterestSupported && device.isExposureModeSupported(expusureMode)){
                    device.exposurePointOfInterest = point
                    device.exposureMode = expusureMode
                }
                
                device.isSubjectAreaChangeMonitoringEnabled = monitorSubjectAreaChange
                device.unlockForConfiguration()
                
            } catch let error as NSError {
                print(error.debugDescription)
            }
        }

    }
    
    func tapped(tapGestureRecognizer: UITapGestureRecognizer) {
        print("tapped.")
        
        if attrText.string == "æœªåˆ†é¡\nâ–²" {
        attrText.mutableString.setString("æœªåˆ†é¡\nâ–¼")
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 17)], range: NSMakeRange(0, 3))
        attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 10)], range: NSMakeRange(4, 1))
        label.attributedText = attrText
        navigationItem.titleView = label
            
            

 
//            let modalViewController = PopupSubjectViewController()
//            modalViewController.modalPresentationStyle = .custom
//            modalViewController.transitioningDelegate = self
//            present(modalViewController, animated: true, completion: nil)
            
        }else {
            attrText.mutableString.setString("æœªåˆ†é¡\nâ–²")
            attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 17)], range: NSMakeRange(0, 3))
            attrText.addAttributes([NSFontAttributeName: UIFont.systemFont(ofSize: 10)], range: NSMakeRange(4, 1))
            label.attributedText = attrText
            navigationItem.titleView = label
            
            // æ–°ã—ã„ View Controller ã‚’ãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤ºã™ã‚‹
            let controller = self.storyboard!.instantiateViewController(withIdentifier: "PopupSubjectViewController")
            controller.modalPresentationStyle = .custom
            controller.transitioningDelegate = self
            self.present(controller, animated: true, completion: {
            })
        }
        
    }
    
    func presentationControllerForPresentedViewController(presented: UIViewController, presentingViewController presenting: UIViewController, sourceViewController source: UIViewController) -> UIPresentationController? {
        return CustomModal(presentedViewController: presented, presenting: presenting)
    }
    
    override func didReceiveMemoryWarning() {
        super.didReceiveMemoryWarning()
        // Dispose of any resources that can be recreated.
    }
    
    
    
}

extension CameraViewController: UIViewControllerTransitioningDelegate {
    
    func presentationController(forPresented presented: UIViewController, presenting: UIViewController?, source: UIViewController) -> UIPresentationController? {
        return CustomPresentationController(presentedViewController: presented, presenting: presenting)

    }
}
